% \emph{Assigned: Dimitri}
(a) is easier to minimize because derivatives are well-defined $\forall \vec{y}$ and $\vec{\omega}$ while the loss in (b) has is not differentiable everywhere (due to the absolute value). (b) is more robust to outliers since it weights less the discrepancy between $y_i$ and $\omega^T x_i$ using an L1 norm while (a) uses an L2 norm grows with a squared relationship with the discrepancy between $y_i$ and $\omega^T x_i$. We can see this if we assume that $|y_i - \omega^T x_i| = 2$ for some $y_i, \omega, x_i$ and for all other examples $x_j$, $j \neq i$, we have $|y_j - \omega^T x_j| = 0$. In (a), the contribution to the loss function would be $4$ while in (b), the contribution to the loss function would be $2$, resulting in total losses of $2$ and $4$, respectively. We can clearly see that outliers in (b) do not contribute as heavily to the loss function as in (a). 